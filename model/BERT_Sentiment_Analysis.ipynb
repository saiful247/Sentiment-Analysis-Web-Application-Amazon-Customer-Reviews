{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b35c1aa-05e4-417e-878e-9d54ef5f8e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91bed6f-cc15-43bd-8a18-e60b96a6e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=pd.read_csv('cleaned_bert_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464b3c29-09ec-4ed6-b829-e9546a6cecc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>purchased device worked advertised never much ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>works expected sprung higher capacity think ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>think worked greathad diff bran gb card went s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bought retail packaging arrived legit orange e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>mini storage doesnt anything else supposed pur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       cleaned_text  \\\n",
       "0           1  purchased device worked advertised never much ...   \n",
       "1           2  works expected sprung higher capacity think ma...   \n",
       "2           3  think worked greathad diff bran gb card went s...   \n",
       "3           4  bought retail packaging arrived legit orange e...   \n",
       "4           5  mini storage doesnt anything else supposed pur...   \n",
       "\n",
       "   sentiment_label  \n",
       "0                0  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d9b5d2b-b083-4f32-9738-83891dfd30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df6.drop(['Unnamed: 0'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43188e6a-3384-49e9-b6c4-29422c41ee9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>purchased device worked advertised never much ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>works expected sprung higher capacity think ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think worked greathad diff bran gb card went s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bought retail packaging arrived legit orange e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mini storage doesnt anything else supposed pur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  sentiment_label\n",
       "0  purchased device worked advertised never much ...                0\n",
       "1  works expected sprung higher capacity think ma...                1\n",
       "2  think worked greathad diff bran gb card went s...                1\n",
       "3  bought retail packaging arrived legit orange e...                1\n",
       "4  mini storage doesnt anything else supposed pur...                0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1656b7f-55bc-4b14-8279-32438f3c7a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19eb3bd6188947d89693d3f8aef736ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3930 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54aeaff2383a4e308e8ac8b3617fcafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/983 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\saifu\\AppData\\Local\\Temp\\ipykernel_8536\\2437357601.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1476' max='1476' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1476/1476 8:48:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>0.287166</td>\n",
       "      <td>0.896236</td>\n",
       "      <td>0.898473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.151600</td>\n",
       "      <td>0.387735</td>\n",
       "      <td>0.911495</td>\n",
       "      <td>0.914037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.421419</td>\n",
       "      <td>0.912513</td>\n",
       "      <td>0.913653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.28716564178466797, 'eval_accuracy': 0.896236012207528, 'eval_f1': 0.8984727705624751, 'eval_runtime': 670.6275, 'eval_samples_per_second': 1.466, 'eval_steps_per_second': 0.183, 'epoch': 3.0}\n",
      "Accuracy: 0.90\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.80      0.75       193\n",
      "    Positive       0.95      0.92      0.93       790\n",
      "\n",
      "    accuracy                           0.90       983\n",
      "   macro avg       0.83      0.86      0.84       983\n",
      "weighted avg       0.90      0.90      0.90       983\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[154  39]\n",
      " [ 63 727]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df6['cleaned_text'], df6['sentiment_label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#Convert Data into Hugging Face Dataset Format\n",
    "train_data = Dataset.from_dict({\"text\": X_train.tolist(), \"label\": y_train.tolist()})\n",
    "test_data = Dataset.from_dict({\"text\": X_test.tolist(), \"label\": y_test.tolist()})\n",
    "\n",
    "#Tokenize the Data\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_data = train_data.map(tokenize_function, batched=True)\n",
    "test_data = test_data.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "Load Pre-trained BERT Model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "#compute_metrics\n",
    "def compute_metrics(p):\n",
    "    predictions = torch.tensor(p.predictions)  # Convert predictions to tensor\n",
    "    preds = torch.argmax(predictions, axis=1).numpy()  # Get the predicted labels\n",
    "    labels = p.label_ids  # True labels\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": classification_report(labels, preds, output_dict=True)[\"weighted avg\"][\"f1-score\"],\n",
    "    }\n",
    "\n",
    "#Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "#Train model\n",
    "trainer.train()\n",
    "\n",
    "#Evaluate the Model\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)\n",
    "\n",
    "#Additional Metrics: Accuracy, Classification Report, Confusion Matrix\n",
    "test_results = trainer.predict(test_data)\n",
    "y_true = test_results.label_ids\n",
    "y_pred = np.argmax(test_results.predictions, axis=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Negative\", \"Positive\"]))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb9ba20-9201-4a7e-a717-a367d40e075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction Function\n",
    "def predict_analysis(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, axis=1).item()\n",
    "    sentiment = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    return f\"The sentiment of the input text is: {sentiment}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ab1366-52ac-4e59-9513-f933a638f946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentiment of the input text is: Positive'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_analysis('Good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bd8f449-1467-4333-8ed8-abbb023d6324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentiment of the input text is: Negative'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_analysis('Not Good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7729234-3c69-4a70-93ff-ab0cb0b6c514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentiment of the input text is: Negative'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_analysis('I hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640f4d84-83e3-42c5-b4fe-581bf36a1d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentiment of the input text is: Positive'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_analysis('I love this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f512c08c-4c1c-46fd-8b77-d47b75a43131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./bert_sentiment_model\n"
     ]
    }
   ],
   "source": [
    "#export directory\n",
    "export_dir = \"./bert_sentiment_model\"\n",
    "\n",
    "#save model\n",
    "model.save_pretrained(export_dir)\n",
    "\n",
    "#save_tokenizer\n",
    "tokenizer.save_pretrained(export_dir)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {export_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c512a637-1f62-49f2-9293-78417a8cb679",
   "metadata": {},
   "source": [
    "The model is saved in model.safetensors this for mat. so if you want to export as pytorch_model.bin use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb357b9-8675-468d-aac9-1f9a832df568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in PyTorch format at ./bert_pytorch_model\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "save_directory = \"./bert_pytorch_model\"\n",
    "model.save_pretrained(save_directory, safe_serialization=False)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model saved in PyTorch format at {save_directory}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
